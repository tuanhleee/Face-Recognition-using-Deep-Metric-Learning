{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "008e60a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 24244.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded OK: (None, 512)\n",
      "Loaded embedding model OK\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# -------- custom function (n·∫øu model c√≥ d√πng) --------\n",
    "\n",
    "\n",
    "def scaling(x, scale=0.10):\n",
    "    return x * scale\n",
    "\n",
    "emb_model = keras.saving.load_model(\n",
    "    \"hf://logasja/FaceNet512\",\n",
    "    custom_objects={\"scaling\": scaling},\n",
    "    compile=False,\n",
    "    safe_mode=False\n",
    ")\n",
    "print(\"Loaded OK:\", emb_model.output_shape)\n",
    "\n",
    "print(\"Loaded embedding model OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42fe0e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Embedded 6\n",
      "‚úì Embedded TuAnh\n",
      "‚úì Embedded pig\n",
      "\n",
      "Saved base.csv with 3 identities\n",
      "    name                                      val_embedding\n",
      "0      6  [0.050949838012456894, 0.019697386771440506, 0...\n",
      "1  TuAnh  [0.028406303375959396, -0.030795753002166748, ...\n",
      "2    pig  [-0.01214636955410242, 0.004847864620387554, -...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------- utils --------\n",
    "def load_face(path, size=(160, 160)):\n",
    "    img = Image.open(path).convert(\"RGB\").resize(size)\n",
    "    x = np.array(img).astype(\"float32\")\n",
    "    x = (x / 127.5) - 1.0   \n",
    "    return x\n",
    "\n",
    "def l2n(x):\n",
    "    return tf.math.l2_normalize(x, axis=-1)\n",
    "\n",
    "def embed_one(image_path):\n",
    "    x = load_face(image_path)[None, ...]  # (1,160,160,3)\n",
    "    e = emb_model(x, training=False)\n",
    "    e = l2n(e)\n",
    "\n",
    "    if isinstance(e, tf.Tensor):\n",
    "        e = e.numpy()\n",
    "\n",
    "    e = e.reshape(-1)\n",
    "    assert e.shape == (512,), f\"Bad embedding shape {e.shape}\"\n",
    "    return e\n",
    "\n",
    "# -------- scan data_test folder --------\n",
    "DATA_DIR = \"/home/tuanh/projet/face_Recognition/data_test/data\"\n",
    "\n",
    "image_paths = sorted(\n",
    "    glob.glob(os.path.join(DATA_DIR, \"*\"))\n",
    ")\n",
    "\n",
    "records = []\n",
    "\n",
    "for path in image_paths:\n",
    "    try:\n",
    "        name = os.path.splitext(os.path.basename(path))[0]  \n",
    "        emb = embed_one(path)\n",
    "\n",
    "        records.append({\n",
    "            \"name\": name,\n",
    "            \"val_embedding\": emb.tolist()\n",
    "        })\n",
    "\n",
    "        print(f\"‚úì Embedded {name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Skip {path}: {e}\")\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df.to_csv(\"base.csv\", index=False)\n",
    "\n",
    "print(f\"\\nSaved base.csv with {len(df)} identities\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef60557",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/tuanh/projet/face_Recognition/data_test/data/Tuanh.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcos\u001b[39m(a,b):\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tf.reduce_sum(a*b, axis=-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m x3 = \u001b[43mload_face\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/home/tuanh/projet/face_Recognition/data_test/data/Tuanh.jpeg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;28;01mNone\u001b[39;00m, ...]\n\u001b[32m     18\u001b[39m x4 = load_face(\u001b[33m\"\u001b[39m\u001b[33m/home/tuanh/projet/face_Recognition/data_test/data/TuAnh2.jpeg\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[38;5;28;01mNone\u001b[39;00m, ...]\n\u001b[32m     21\u001b[39m e3 = emb_model(x3, training=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mload_face\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_face\u001b[39m(path):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     img = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m.convert(\u001b[33m\"\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m\"\u001b[39m).resize((\u001b[32m160\u001b[39m,\u001b[32m160\u001b[39m))\n\u001b[32m      6\u001b[39m     x = np.array(img).astype(\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m     x = (x / \u001b[32m127.5\u001b[39m) - \u001b[32m1.0\u001b[39m   \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projet/face_Recognition/venv/lib/python3.11/site-packages/PIL/Image.py:3512\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3510\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_path(fp):\n\u001b[32m   3511\u001b[39m     filename = os.fspath(fp)\n\u001b[32m-> \u001b[39m\u001b[32m3512\u001b[39m     fp = builtins.open(filename, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   3513\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3514\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/tuanh/projet/face_Recognition/data_test/data/Tuanh.jpeg'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_face(path):\n",
    "    img = Image.open(path).convert(\"RGB\").resize((160,160))\n",
    "    x = np.array(img).astype(\"float32\")\n",
    "    x = (x / 127.5) - 1.0   \n",
    "    return x\n",
    "\n",
    "\n",
    "def l2n(x): \n",
    "    return tf.math.l2_normalize(x, axis=-1)\n",
    "\n",
    "def cos(a,b):\n",
    "    return tf.reduce_sum(a*b, axis=-1)\n",
    "\n",
    "x3 = load_face(\"/home/tuanh/projet/face_Recognition/data_test/data/TuAnh.jpeg\")[None, ...]\n",
    "x4 = load_face(\"/home/tuanh/projet/face_Recognition/data_test/data/TuAnh2.jpeg\")[None, ...]\n",
    "\n",
    "\n",
    "e3 = emb_model(x3, training=False)\n",
    "e3 = l2n(e3)\n",
    "\n",
    "e4 = emb_model(x4, training=False)\n",
    "e4 = l2n(e4)\n",
    "\n",
    "print(\"same cosine:\", cos(e3,e4).numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c36b498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/tuanh/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 üöÄ 2026-1-13 Python-3.11.9 torch-2.7.0+cu126 CUDA:0 (NVIDIA GeForce RTX 3060, 11910MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5x summary: 182 layers, 7246518 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "YOLOV5_WEIGHTS = \"/home/tuanh/projet/face_Recognition/best.pt\"\n",
    "\n",
    "det = torch.hub.load(\n",
    "    \"ultralytics/yolov5\",\n",
    "    \"custom\",\n",
    "    path=YOLOV5_WEIGHTS,\n",
    "    force_reload=False\n",
    ")\n",
    "det.conf = 0.35\n",
    "det.iou = 0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29700a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL NAMES = {0: 'face'}\n"
     ]
    }
   ],
   "source": [
    "# sau khi load det = torch.hub.load(...)\n",
    "\n",
    "print(\"MODEL NAMES =\", det.names)     # th∆∞·ªùng l√† dict: {0:'face'} ho·∫∑c list ['face',...]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
